{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
    "\n",
    "path_main_folder = '/home/antorosi/Documents/Prediction'\n",
    "sys.path.append(path_main_folder)\n",
    "\n",
    "from conso.load_shape_data import load_data_conso, get_uniformed_data_conso, change_granularity, get_x_y_prediction_conso, get_train_test_sets, normalized_dataset, select_variables\n",
    "from models.feedforward_NN import FeedForward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and shape data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "path_data = os.path.join(path_main_folder, 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_data_conso = load_data_conso(path_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniformization\n",
    "data_conso_df, dict_colnames_conso = get_uniformed_data_conso(dict_data_conso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Granularity from 15 min to 1H\n",
    "data_conso_df = change_granularity(data_conso_df, granularity=\"1H\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get x and y from prediction\n",
    "x_conso, y_conso, dict_colnames_conso = get_x_y_prediction_conso(data_conso_df, dict_colnames_conso, horizon_length=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_out = os.path.join(path_main_folder, 'out', 'benchmark_0')\n",
    "if not os.path.exists(path_out):\n",
    "    os.mkdir(path_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_selected_var = {'cmcah':['calendar', 'conso', 'holiday_days','meteo'], 'cmca':['calendar', 'conso','meteo']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_nb_hidden_layers = [2,4,6,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dropout = [0,0.05,0.1,0.15,0.20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_epochs=400\n",
    "batch_size=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "combination = list(itertools.product(list_nb_hidden_layers, list_dropout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_test_start = datetime.datetime(year=2016, month=6, day=11)\n",
    "date_test_end = datetime.datetime(year=2017, month=6, day=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare results wrap up \n",
    "results_df = pd.DataFrame(columns=['name', 'layer_dims','dropout_rates','batchsize',\n",
    "                                           'best_iter', 'train_mse',\n",
    "                                           'train_mae', 'train_mape',\n",
    "                                           'test_mse', 'test_mae',\n",
    "                                           'test_mape'])\n",
    "path_results = path_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================= Model 1/20 =========================\n",
      "model: \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_input (InputLayer)     (None, 153)               0         \n",
      "_________________________________________________________________\n",
      "dense_hidden_0 (Dense)       (None, 153)               23562     \n",
      "_________________________________________________________________\n",
      "dense_hidden_1 (Dense)       (None, 153)               23562     \n",
      "_________________________________________________________________\n",
      "dense_output (Dense)         (None, 1)                 154       \n",
      "=================================================================\n",
      "Total params: 47,278\n",
      "Trainable params: 47,278\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "--- START TRAINING ---\n",
      "\n",
      "Train on 30236 samples, validate on 8759 samples\n",
      "Epoch 1/10\n",
      "30236/30236 [==============================] - 0s 12us/step - loss: 3148839337.2668 - mean_absolute_percentage_error: 99.9553 - mean_absolute_error: 54836.0380 - val_loss: 3115906241.4979 - val_mean_absolute_percentage_error: 99.8292 - val_mean_absolute_error: 54434.1484\n",
      "Epoch 2/10\n",
      "30236/30236 [==============================] - 0s 13us/step - loss: 3120357382.1976 - mean_absolute_percentage_error: 99.5089 - mean_absolute_error: 54589.5632 - val_loss: 3051175870.8090 - val_mean_absolute_percentage_error: 98.7922 - val_mean_absolute_error: 53868.3475\n",
      "Epoch 3/10\n",
      "30236/30236 [==============================] - 0s 11us/step - loss: 3010812569.2139 - mean_absolute_percentage_error: 97.7633 - mean_absolute_error: 53625.8907 - val_loss: 2859560018.0550 - val_mean_absolute_percentage_error: 95.6320 - val_mean_absolute_error: 52144.2215\n",
      "Epoch 4/10\n",
      "30236/30236 [==============================] - 0s 10us/step - loss: 2752563080.4498 - mean_absolute_percentage_error: 93.4462 - mean_absolute_error: 51247.5369 - val_loss: 2478305950.2646 - val_mean_absolute_percentage_error: 88.8858 - val_mean_absolute_error: 48461.6240\n",
      "Epoch 5/10\n",
      "30236/30236 [==============================] - 0s 9us/step - loss: 2309768938.1558 - mean_absolute_percentage_error: 85.3439 - mean_absolute_error: 46774.5063 - val_loss: 1919302084.4498 - val_mean_absolute_percentage_error: 77.4401 - val_mean_absolute_error: 42212.7182\n",
      "Epoch 6/10\n",
      "30236/30236 [==============================] - 0s 11us/step - loss: 1736399226.1918 - mean_absolute_percentage_error: 72.8446 - mean_absolute_error: 39867.4943 - val_loss: 1319493585.2294 - val_mean_absolute_percentage_error: 61.5420 - val_mean_absolute_error: 33495.7789\n",
      "Epoch 7/10\n",
      "30236/30236 [==============================] - 0s 9us/step - loss: 1198283479.1988 - mean_absolute_percentage_error: 57.8198 - mean_absolute_error: 31481.4963 - val_loss: 901862560.1644 - val_mean_absolute_percentage_error: 47.5085 - val_mean_absolute_error: 25641.1814\n",
      "Epoch 8/10\n",
      "30236/30236 [==============================] - 0s 9us/step - loss: 872383511.6899 - mean_absolute_percentage_error: 47.0085 - mean_absolute_error: 25339.9430 - val_loss: 765360758.3587 - val_mean_absolute_percentage_error: 42.4748 - val_mean_absolute_error: 22933.0627\n",
      "Epoch 9/10\n",
      "30236/30236 [==============================] - 0s 9us/step - loss: 766042903.3766 - mean_absolute_percentage_error: 43.3300 - mean_absolute_error: 23263.3386 - val_loss: 763154294.3953 - val_mean_absolute_percentage_error: 41.8180 - val_mean_absolute_error: 22688.0959\n",
      "Epoch 10/10\n",
      "30236/30236 [==============================] - 0s 9us/step - loss: 746277450.9051 - mean_absolute_percentage_error: 42.5400 - mean_absolute_error: 22850.9708 - val_loss: 765185918.8565 - val_mean_absolute_percentage_error: 41.6398 - val_mean_absolute_error: 22645.1322\n",
      "                            name  layer_dims dropout_rates batchsize  \\\n",
      "0  b0_FFNN_l153*2_d0*2_cmca_norm  [153, 153]        [0, 0]      1000   \n",
      "\n",
      "  best_iter     train_mse     train_mae  train_mape      test_mse  \\\n",
      "0         9  7.507902e+08  22944.644626   42.730612  7.631543e+08   \n",
      "\n",
      "       test_mae  test_mape  \n",
      "0  22688.095757   41.81803  \n",
      "========================= Model 2/20 =========================\n",
      "model: \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_input (InputLayer)     (None, 153)               0         \n",
      "_________________________________________________________________\n",
      "dense_hidden_0 (Dense)       (None, 153)               23562     \n",
      "_________________________________________________________________\n",
      "dropout_hidden_0 (Dropout)   (None, 153)               0         \n",
      "_________________________________________________________________\n",
      "dense_hidden_1 (Dense)       (None, 153)               23562     \n",
      "_________________________________________________________________\n",
      "dropout_hidden_1 (Dropout)   (None, 153)               0         \n",
      "_________________________________________________________________\n",
      "dense_output (Dense)         (None, 1)                 154       \n",
      "=================================================================\n",
      "Total params: 47,278\n",
      "Trainable params: 47,278\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "--- START TRAINING ---\n",
      "\n",
      "Train on 30236 samples, validate on 8759 samples\n",
      "Epoch 1/10\n",
      "30236/30236 [==============================] - 1s 17us/step - loss: 3148733495.4740 - mean_absolute_percentage_error: 99.9515 - mean_absolute_error: 54834.5386 - val_loss: 3115239727.7132 - val_mean_absolute_percentage_error: 99.8123 - val_mean_absolute_error: 54426.6523\n",
      "Epoch 2/10\n",
      "30236/30236 [==============================] - 0s 14us/step - loss: 3118119184.0529 - mean_absolute_percentage_error: 99.4614 - mean_absolute_error: 54566.6954 - val_loss: 3045373121.2056 - val_mean_absolute_percentage_error: 98.6705 - val_mean_absolute_error: 53809.4635\n",
      "Epoch 3/10\n",
      "30236/30236 [==============================] - 0s 12us/step - loss: 3000885388.1074 - mean_absolute_percentage_error: 97.5487 - mean_absolute_error: 53522.2732 - val_loss: 2839725500.3685 - val_mean_absolute_percentage_error: 95.2071 - val_mean_absolute_error: 51936.1554\n",
      "Epoch 4/10\n",
      "30236/30236 [==============================] - 0s 10us/step - loss: 2725887587.8058 - mean_absolute_percentage_error: 92.8626 - mean_absolute_error: 50959.0837 - val_loss: 2435043648.9864 - val_mean_absolute_percentage_error: 87.8429 - val_mean_absolute_error: 47951.6408\n",
      "Epoch 5/10\n",
      "30236/30236 [==============================] - 0s 10us/step - loss: 2258629251.2004 - mean_absolute_percentage_error: 84.0540 - mean_absolute_error: 46133.7564 - val_loss: 1851118541.7586 - val_mean_absolute_percentage_error: 75.3943 - val_mean_absolute_error: 41208.0425\n",
      "Epoch 6/10\n",
      "30236/30236 [==============================] - 0s 10us/step - loss: 1669816873.2838 - mean_absolute_percentage_error: 70.6435 - mean_absolute_error: 38775.2380 - val_loss: 1251220354.9592 - val_mean_absolute_percentage_error: 58.8197 - val_mean_absolute_error: 32131.3678\n",
      "Epoch 7/10\n",
      "30236/30236 [==============================] - 0s 12us/step - loss: 1142726460.0037 - mean_absolute_percentage_error: 55.6337 - mean_absolute_error: 30370.4888 - val_loss: 870938767.9470 - val_mean_absolute_percentage_error: 46.2037 - val_mean_absolute_error: 24991.2298\n",
      "Epoch 8/10\n",
      "30236/30236 [==============================] - 0s 11us/step - loss: 852448899.1242 - mean_absolute_percentage_error: 46.2242 - mean_absolute_error: 24935.4241 - val_loss: 766252085.8180 - val_mean_absolute_percentage_error: 42.3975 - val_mean_absolute_error: 22912.7362\n",
      "Epoch 9/10\n",
      "30236/30236 [==============================] - 0s 11us/step - loss: 765474541.2801 - mean_absolute_percentage_error: 43.2316 - mean_absolute_error: 23225.0824 - val_loss: 764357475.6461 - val_mean_absolute_percentage_error: 41.8184 - val_mean_absolute_error: 22695.5467\n",
      "Epoch 10/10\n",
      "30236/30236 [==============================] - 0s 11us/step - loss: 747853384.1111 - mean_absolute_percentage_error: 42.5603 - mean_absolute_error: 22869.5208 - val_loss: 763455987.2314 - val_mean_absolute_percentage_error: 41.5685 - val_mean_absolute_error: 22612.5444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               name  layer_dims dropout_rates batchsize  \\\n",
      "0  b0_FFNN_l153*2_d0.05*2_cmca_norm  [153, 153]  [0.05, 0.05]      1000   \n",
      "\n",
      "  best_iter     train_mse     train_mae  train_mape      test_mse  \\\n",
      "0        10  7.409149e+08  22746.755045   42.315047  7.634560e+08   \n",
      "\n",
      "       test_mae  test_mape  \n",
      "0  22612.544849  41.568486  \n",
      "========================= Model 3/20 =========================\n",
      "model: \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_input (InputLayer)     (None, 153)               0         \n",
      "_________________________________________________________________\n",
      "dense_hidden_0 (Dense)       (None, 153)               23562     \n",
      "_________________________________________________________________\n",
      "dropout_hidden_0 (Dropout)   (None, 153)               0         \n",
      "_________________________________________________________________\n",
      "dense_hidden_1 (Dense)       (None, 153)               23562     \n",
      "_________________________________________________________________\n",
      "dropout_hidden_1 (Dropout)   (None, 153)               0         \n",
      "_________________________________________________________________\n",
      "dense_output (Dense)         (None, 1)                 154       \n",
      "=================================================================\n",
      "Total params: 47,278\n",
      "Trainable params: 47,278\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "--- START TRAINING ---\n",
      "\n",
      "Train on 30236 samples, validate on 8759 samples\n",
      "Epoch 1/10\n",
      "30236/30236 [==============================] - 0s 14us/step - loss: 3148892568.9768 - mean_absolute_percentage_error: 99.9547 - mean_absolute_error: 54836.1048 - val_loss: 3115720920.8211 - val_mean_absolute_percentage_error: 99.8209 - val_mean_absolute_error: 54431.0750\n",
      "Epoch 2/10\n",
      "30236/30236 [==============================] - 0s 13us/step - loss: 3118939973.6304 - mean_absolute_percentage_error: 99.4707 - mean_absolute_error: 54572.9076 - val_loss: 3046122383.4173 - val_mean_absolute_percentage_error: 98.6665 - val_mean_absolute_error: 53811.6278\n",
      "Epoch 3/10\n",
      "30236/30236 [==============================] - 0s 11us/step - loss: 3000580667.5719 - mean_absolute_percentage_error: 97.5138 - mean_absolute_error: 53511.2016 - val_loss: 2836958186.7373 - val_mean_absolute_percentage_error: 95.0791 - val_mean_absolute_error: 51887.6354\n",
      "Epoch 4/10\n",
      "30236/30236 [==============================] - 0s 11us/step - loss: 2720724024.2191 - mean_absolute_percentage_error: 92.6572 - mean_absolute_error: 50875.7275 - val_loss: 2423196551.1022 - val_mean_absolute_percentage_error: 87.3891 - val_mean_absolute_error: 47761.2796\n",
      "Epoch 5/10\n",
      "30236/30236 [==============================] - 0s 10us/step - loss: 2244914011.7624 - mean_absolute_percentage_error: 83.4905 - mean_absolute_error: 45894.5774 - val_loss: 1829536536.5946 - val_mean_absolute_percentage_error: 74.3770 - val_mean_absolute_error: 40766.3578\n",
      "Epoch 6/10\n",
      "30236/30236 [==============================] - 0s 10us/step - loss: 1648039743.4497 - mean_absolute_percentage_error: 69.5910 - mean_absolute_error: 38304.7868 - val_loss: 1231716436.1886 - val_mean_absolute_percentage_error: 57.6097 - val_mean_absolute_error: 31602.8117\n",
      "Epoch 7/10\n",
      "30236/30236 [==============================] - 0s 11us/step - loss: 1130444025.9040 - mean_absolute_percentage_error: 54.8853 - mean_absolute_error: 30054.5415 - val_loss: 870106430.2062 - val_mean_absolute_percentage_error: 46.0228 - val_mean_absolute_error: 24944.9106\n",
      "Epoch 8/10\n",
      "30236/30236 [==============================] - 0s 11us/step - loss: 852398601.3134 - mean_absolute_percentage_error: 46.1250 - mean_absolute_error: 24920.9856 - val_loss: 770556189.8153 - val_mean_absolute_percentage_error: 42.5336 - val_mean_absolute_error: 22985.8234\n",
      "Epoch 9/10\n",
      "30236/30236 [==============================] - 0s 10us/step - loss: 769602386.4067 - mean_absolute_percentage_error: 43.3711 - mean_absolute_error: 23304.1621 - val_loss: 763884041.8203 - val_mean_absolute_percentage_error: 41.8241 - val_mean_absolute_error: 22695.6432\n",
      "Epoch 10/10\n",
      "30236/30236 [==============================] - 0s 11us/step - loss: 750916708.6694 - mean_absolute_percentage_error: 42.6471 - mean_absolute_error: 22921.4355 - val_loss: 760481409.5088 - val_mean_absolute_percentage_error: 41.4990 - val_mean_absolute_error: 22573.6618\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-71e2d0282799>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m# Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# Get result and put it in results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Prediction/models/feedforward_NN.py\u001b[0m in \u001b[0;36mmain_train\u001b[0;34m(self, dataset, training_epochs, batch_size, callbacks, verbose)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0msummary_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyze_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Prediction/models/feedforward_NN.py\u001b[0m in \u001b[0;36manalyze_history\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_best_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0my_hat_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/home/antorosi/PycharmProjects/KERAS-TS-VENV/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1840\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m         return self._predict_loop(f, ins, batch_size=batch_size,\n\u001b[0;32m-> 1842\u001b[0;31m                                   verbose=verbose, steps=steps)\n\u001b[0m\u001b[1;32m   1843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1844\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/local/home/antorosi/PycharmProjects/KERAS-TS-VENV/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1338\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m                     \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m                     \u001b[0;31m# Pre-allocate the results arrays.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_out\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_outs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for gen_name, selected_variables in dict_selected_var.items():\n",
    "    \n",
    "    # Prepare dataset\n",
    "    x_conso_selected_var = select_variables(x_conso, dict_colnames_conso, selected_variables)\n",
    "    dataset, dict_ds = get_train_test_sets(x_conso_selected_var, y_conso, date_test_start, date_test_end)\n",
    "    dataset = normalized_dataset(dataset, dict_colnames_conso)\n",
    "    \n",
    "    nb_hidden_units = dataset['train']['x'].shape[1]\n",
    "    \n",
    "    for idx, (nb_hidden_layers, dropout) in enumerate(combination):\n",
    "        \n",
    "        print('========================= Model {}/{} ========================='.format(idx+1, len(combination)))\n",
    "        \n",
    "        # Prepare model characteristics\n",
    "        name_model = 'b0_FFNN_l{}*{}_d{}*{}_{}_norm'.format(nb_hidden_units, nb_hidden_layers,\n",
    "                                                            dropout, nb_hidden_layers, \n",
    "                                                            gen_name)\n",
    "        \n",
    "        # Compile model\n",
    "        model = FeedForward(name=name_model, output=path_out, input_dim=nb_hidden_units, output_dim=1, \n",
    "                   l_dims=[nb_hidden_units]*nb_hidden_layers, dropout_rates=[dropout]*nb_hidden_layers,\n",
    "                   loss = 'mean_squared_error', metrics = ['mape', 'mae'])\n",
    "        \n",
    "        # Prepare callbacks\n",
    "        callbacks = []\n",
    "        early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=150,\n",
    "                                                           verbose=0, mode='auto')\n",
    "\n",
    "        model_checkpoint = ModelCheckpoint(os.path.join(path_out, name_model, 'models', 'model-best.hdf5'),\n",
    "                                                   monitor='val_loss',\n",
    "                                                   verbose=0, save_best_only=True, save_weights_only=False,\n",
    "                                                   mode='auto', period=1)\n",
    "\n",
    "        tensorboard_model = TensorBoard(log_dir=os.path.join(path_out, name_model, 'results', 'logs', time.strftime('%Y-%m-%d_%H:%M', time.localtime(time.time()))))\n",
    "        tensorboard_summary = TensorBoard(log_dir=os.path.join(path_out, 'logs', name_model))\n",
    "        \n",
    "\n",
    "        callbacks.append(early_stop)\n",
    "        callbacks.append(model_checkpoint)\n",
    "        callbacks.append(tensorboard_model)\n",
    "        callbacks.append(tensorboard_summary)\n",
    "        \n",
    "        # Train model\n",
    "        model.main_train(dataset, training_epochs=training_epochs, batch_size=batch_size, callbacks=callbacks)\n",
    "        \n",
    "        # Get result and put it in results\n",
    "        _, result = model.analyze_history(dataset)\n",
    "        \n",
    "        results_df= results_df.append(result, ignore_index=True)\n",
    "        results_df.to_csv(os.path.join(path_results, 'b0_results.csv'), sep=';')\n",
    "    \n",
    "        # Reset graph\n",
    "        K.clear_session()\n",
    "        import tensorflow as tf\n",
    "        tf.reset_default_graph()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
